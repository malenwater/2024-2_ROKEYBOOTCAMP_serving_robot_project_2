import cv2
import numpy as np

# === 1. í¬ìŠ¤í„°ì˜ ë¯¸ë¦¬ ì •ì˜ëœ 3D ì›”ë“œ ì¢Œí‘œ (m ë‹¨ìœ„) ===
object_points = np.array([
    [0.0, 0.0, 0.0],   # í¬ìŠ¤í„° ì™¼ìª½ ìƒë‹¨ (ê¸°ì¤€ì )
    [0.5, 0.0, 0.0],   # í¬ìŠ¤í„° ì˜¤ë¥¸ìª½ ìƒë‹¨
    [0.0, 0.7, 0.0],   # í¬ìŠ¤í„° ì™¼ìª½ í•˜ë‹¨
    [0.25, 0.35, 0.0], # í¬ìŠ¤í„° ì¤‘ì•™ íŠ¹ì • íŒ¨í„´
    [0.1, 0.2, 0.0],   # ë‚´ë¶€ SIFT íŠ¹ì§•ì  1
    [0.3, 0.5, 0.0]    # ë‚´ë¶€ SIFT íŠ¹ì§•ì  2
], dtype=np.float32)

# === 2. SIFT íŠ¹ì§•ì  ê²€ì¶œ ===
def extract_sift_features(image):
    if image is None:
        print("âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨! íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None, None
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(image, None)
    return keypoints, descriptors

# ê¸°ì¤€ í¬ìŠ¤í„° ì´ë¯¸ì§€ ë¡œë“œ
poster_img = cv2.imread('/home/minho/week7_ws/KDT/KDT/poster_reference.png', cv2.IMREAD_GRAYSCALE)
if poster_img is None:
    print("âŒ í¬ìŠ¤í„° ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'poster_reference.jpg' ê²½ë¡œ í™•ì¸!")
    exit()

poster_kp, poster_des = extract_sift_features(poster_img)

# === 3. ì‹¤ì‹œê°„ ì›¹ìº  ìº¡ì²˜ ===
cap = cv2.VideoCapture(0)
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("âŒ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        break

    # ì›¹ìº  í”„ë ˆì„ì„ í‘ë°± ì´ë¯¸ì§€ë¡œ ë³€í™˜
    camera_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    camera_kp, camera_des = extract_sift_features(camera_img)

    if camera_des is not None and poster_des is not None:
        # === 4. íŠ¹ì§•ì  ë§¤ì¹­ (KNN ë§¤ì¹­) ===
        bf = cv2.BFMatcher()
        matches = bf.knnMatch(poster_des, camera_des, k=2)

        # ì¢‹ì€ ë§¤ì¹­ì  ì„ ë³„ (Lowe's Ratio Test)
        good_matches = []
        for m, n in matches:
            if m.distance < 0.85 * n.distance:
                good_matches.append(m)

        print(f"ğŸ”¹ ê²€ì¶œëœ ë§¤ì¹­ëœ íŠ¹ì§•ì  ê°œìˆ˜: {len(good_matches)}")

        # object_points ê°œìˆ˜(6ê°œ)ì— ë§ì¶° image_pointsë„ 6ê°œë§Œ ì„ íƒ
        if len(good_matches) >= len(object_points):
            selected_matches = good_matches[:len(object_points)]  # ìƒìœ„ 6ê°œë§Œ ì„ íƒ
            image_points = np.array([camera_kp[m.trainIdx].pt for m in selected_matches], dtype=np.float32)

            print(f"ğŸ”¹ solvePnP ì‹¤í–‰ - ëŒ€ì‘ì  ê°œìˆ˜: {len(image_points)}")

            # === 5. PnP ìˆ˜í–‰í•˜ì—¬ ë³€í™˜ í–‰ë ¬(R, t) ê³„ì‚° ===
            K = np.array([[1000, 0, 320], [0, 1000, 240], [0, 0, 1]], dtype=np.float32)
            dist_coeffs = np.zeros(4)

            success, rvec, tvec = cv2.solvePnP(object_points, image_points, K, dist_coeffs)

            if success:
                R, _ = cv2.Rodrigues(rvec)
                T = np.eye(4)
                T[:3, :3] = R
                T[:3, 3] = tvec.flatten()

                print("âœ… Rotation Vector (rvec):\n", rvec)
                print("âœ… Translation Vector (tvec):\n", tvec)
                print("âœ… Transformation Matrix (T):\n", T)

            # === 6. ë§¤ì¹­ëœ íŠ¹ì§•ì  ì‹œê°í™” ===
            matched_img = cv2.drawMatches(poster_img, poster_kp, frame, camera_kp, good_matches, None,
                                          flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
            cv2.imshow("Feature Matching", matched_img)

    cv2.imshow("Webcam", frame)
    if cv2.waitKey(1) & 0xFF == 27:  # ESC í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
        break

cap.release()
cv2.destroyAllWindows()